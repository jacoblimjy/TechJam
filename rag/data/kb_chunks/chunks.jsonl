{"id": "65ad4ee9-01df-42c6-bbc6-1f2ee0275104", "text": "Date Published: 09/23/2024 09:00 PM", "metadata": {"source_path": "data/kb_raw/California state law.txt", "h1": "", "h2": "", "h3": "", "law_name": "Protecting Our Kids from Social Media Addiction Act", "region": "US-CA", "article_or_section": "", "source": "https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240SB976"}}
{"id": "1461bb60-d563-4f4e-9c04-6542d1347f93", "text": "## Senate Bill No. 976", "metadata": {"h2": "Senate Bill No. 976", "source_path": "data/kb_raw/California state law.txt", "h1": "", "h3": "", "law_name": "Protecting Our Kids from Social Media Addiction Act", "region": "US-CA", "article_or_section": "", "source": "https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240SB976"}}
{"id": "eaa1985a-f97a-4efe-b143-df1fb829df18", "text": "## CHAPTER 321  \nAn act to add Chapter 24 (commencing with Section 27000) to Division 20 of the Health and Safety Code, relating to youth addiction.  \n[ Approved by Governor September 20, 2024. Filed with Secretary of State September 20, 2024. ]", "metadata": {"h2": "CHAPTER 321", "source_path": "data/kb_raw/California state law.txt", "h1": "", "h3": "", "law_name": "Protecting Our Kids from Social Media Addiction Act", "region": "US-CA", "article_or_section": "", "source": "https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240SB976"}}
{"id": "3be5ec5b-47a3-4dd6-a806-f5cb08525c41", "text": "## THE PEOPLE OF THE STATE OF CALIFORNIA DO ENACT AS FOLLOWS:  \nSECTION 1. The Legislature finds and declares the following:  \n- (a) Social media provides an important tool for communication and information sharing. Approximately 95 percent of 13- to 17-year-olds, inclusive, say that they use at least one social media platform, and more than one-third report using social media almost constantly.\n- (b) However, some social media platforms have evolved to include addictive features, including the algorithmic delivery of content and other design features, that pose a significant risk of harm to the mental health and wellbeing of children and adolescents.\n- (c) As the United States Surgeon General has reported, recent evidence has identified 'reasons for concern' about social media usage by children and adolescents. This evidence includes a study concluding that the risk of poor mental health outcomes doubles for children and adolescents who use social media at least three hours a day and research finding that social media usage is linked to a variety of negative health outcomes, including low self-esteem and disordered eating, for adolescent girls.\n- (d) Heavier usage of social media also leads to less healthy sleep patterns and sleep quality, which can in turn exacerbate both physical and mental health problems.\n- (e) Further, social media usage is more strongly associated with negative mental health outcomes, including depressive symptoms and self-harm behaviors, than is consumption of other forms of media such as television or electronic games.\n- (f) Both California and the country as a whole are facing an ongoing youth mental health crisis, with rates of adolescent suicides, depressive episodes, and feelings of sadness and hopelessness on the rise in recent years.\n- (g) For these reasons, it is essential that California act to ensure that social media platforms obtain parental consent before exposing children and adolescents to harmful and addictive social media features.\n- SEC. 2. Chapter 24 (commencing with Section 27000) is added to Division 20 of the Health and Safety Code, to read:", "metadata": {"h2": "THE PEOPLE OF THE STATE OF CALIFORNIA DO ENACT AS FOLLOWS:", "source_path": "data/kb_raw/California state law.txt", "h1": "", "h3": "", "law_name": "Protecting Our Kids from Social Media Addiction Act", "region": "US-CA", "article_or_section": "", "source": "https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240SB976"}}
{"id": "91dd3aa7-03f1-4361-82b3-163a34b5b9a4", "text": "## LEGISLATIVE COUNSEL'S DIGEST  \nSB 976, Skinner. Protecting Our Kids from Social Media Addiction Act.  \nExisting law, the California Age-Appropriate Design Code Act, requires, beginning July 1, 2024, a business that provides an online service, product, or feature likely to be accessed by children to comply with certain requirements. The act requires the business to complete a data protection impact assessment addressing, among other things, whether the design could harm children and whether and how the online product, service, or feature uses system design features to increase, sustain, or extend use of the online product, service, or feature by children, including the automatic playing of media, rewards for time spent, and notifications. Existing law prohibits the business from using the personal information of any child in a way that the business knows, or has reason to know, is materially detrimental to the physical health, mental health, or well-being of a child.  \nExisting law, the Privacy Rights for California Minors in the Digital World, prohibits an operator of an internet website, online service, online application, or mobile application from specified conduct when minors are involved, including the marketing or advertising of alcoholic beverages, firearms, or certain other products or services. Existing law sets forth other related protections for minors, including under the California Consumer Privacy Act of 2018 and the California Privacy Rights Act of 2020.  \nThis bill, the Protecting Our Kids from Social Media Addiction Act, would make it unlawful for the operator of an addictive internet-based service or application, as defined, to provide an addictive feed to a user, unless the operator does not have actual knowledge that the user is a minor; commencing January 1, 2027, has reasonably determined that the user is not a minor; or has obtained verifiable parental consent to provide an addictive feed to the user who is a minor.  \nThe bill would define 'addictive feed' as an internet website, online service, online application, or mobile application, in which multiple pieces of media generated or shared by users are recommended, selected, or prioritized for display to a user based on information provided by the user, or otherwise associated with the user or the user's device, as specified, unless any of certain conditions are met.  \nThe bill would make it unlawful for the operator of an addictive internet-based service or application, between the hours of 12 a.m. and 6 a.m., in the user's local time zone, and between the hours of 8 a.m. and 3 p.m., Monday through Friday from September through May in the user's local time zone, to send notifications to a user if the operator has actual knowledge that the user is a minor or, commencing January 1, 2027, has not reasonably determined that the user is not a minor, unless the operator has obtained verifiable parental consent to send those notifications, as specified. The bill would set forth related provisions for certain access controls determined by the verified parent through a mechanism provided by the operator.  \nMy Favorites  \nUnder the bill, a parent's provision of consent or use of a mechanism, as described above, would not waive, release, otherwise limit, or serve as a defense to, any claim that the parent, or that the user who is a minor or was a minor at the time of using the internet-based service or application, might have against the operator regarding any harm to the mental health or well-being of the user.  \nThe bill would require an operator to annually disclose the number of minor users of its addictive internet-based service or application, and of that total the number for whom the operator has received verifiable parental consent to provide an addictive feed, and the number of minor users as to whom the access controls are or are not enabled.", "metadata": {"h2": "LEGISLATIVE COUNSEL'S DIGEST", "source_path": "data/kb_raw/California state law.txt", "h1": "", "h3": "", "law_name": "Protecting Our Kids from Social Media Addiction Act", "region": "US-CA", "article_or_section": "", "source": "https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240SB976"}}
{"id": "007c4347-a1b3-4c4a-8ea2-6a7d5b0c0669", "text": "The bill would require an operator to annually disclose the number of minor users of its addictive internet-based service or application, and of that total the number for whom the operator has received verifiable parental consent to provide an addictive feed, and the number of minor users as to whom the access controls are or are not enabled.  \nUnder the bill, these provisions would only be enforced in a civil action brought in the name of the people of the State of California by the Attorney General. The bill would require the Attorney General to adopt regulations to further the purposes of these provisions, including regulations regarding age assurance and parental consent by January 1, 2027. The bill would authorize the Attorney General to adopt regulations that provide for exceptions to these provisions, but only if those exceptions further the purpose of protecting minors. The bill would require the Attorney General, in promulgating regulations, to solicit public comment regarding the impact that any regulation might have based on certain nondiscrimination characteristics set forth in existing law.  \nThe bill would make these provisions severable.  \nVote: majority Appropriation: no Fiscal Committee: yes Local Program: no", "metadata": {"h2": "LEGISLATIVE COUNSEL'S DIGEST", "source_path": "data/kb_raw/California state law.txt", "h1": "", "h3": "", "law_name": "Protecting Our Kids from Social Media Addiction Act", "region": "US-CA", "article_or_section": "", "source": "https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240SB976"}}
{"id": "b3e8166f-08b9-46e8-8f05-ade3b16ad93a", "text": "## CHAPTER 24. Protecting Our Kids from Social Media Addiction Act  \n27000. This chapter shall be known, and may be cited, as the Protecting Our Kids from Social Media Addiction Act.  \n- 27000.5. For purposes of this chapter, the following terms have the following meanings:\n- (a) 'Addictive feed' means an internet website, online service, online application, or mobile application, or a portion thereof, in which multiple pieces of media generated or shared by users are, either concurrently or sequentially, recommended, selected, or prioritized for display to a user based, in whole or in part, on information provided by the user, or otherwise associated with the user or the user's device, unless any of the following conditions are met, alone or in combination with one another:\n- (1) The information is not persistently associated with the user or user's device, and does not concern the user's previous interactions with media generated or shared by others.\n- (2) The information consists of search terms that are not persistently associated with the user or user's device.\n- (3) The information consists of user-selected privacy or accessibility settings, technical information concerning the user's device, or device communications or signals concerning whether the user is a minor.\n- (4) The user expressly and unambiguously requested the specific media or media by the author, creator, or poster of the media, or the blocking, prioritization, or deprioritization of such media, provided that the media is not recommended, selected, or prioritized for display based, in whole or in part, on other information associated with the user or the user's device, except as otherwise permitted by this chapter and, in the case of audio or video content, is not automatically played.\n- (5) The media consists of direct, private communications between users.\n- (6) The media recommended, selected, or prioritized for display is exclusively the next media in a preexisting sequence from the same author, creator, poster, or source and, in the case of audio or video content, is not automatically played.\n- (7) The recommendation, selection, or prioritization of the media is necessary to comply with this chapter or any regulations promulgated pursuant to this chapter.\n- (b) (1) 'Addictive internet-based service or application' means an internet website, online service, online application, or mobile application, including, but not limited to, a 'social media platform' as defined in Section 22675 of the Business and Professions Code, that offers users or provides users with an addictive feed as a significant part of the service provided by that internet website, online service, online application, or mobile application.\n- (2) 'Addictive internet-based service or application' does not apply to either of the following:\n- (A) An internet website, online service, online application, or mobile application for which interactions between users are limited to commercial transactions or to consumer reviews of products, sellers, services, events, or places, or any combination thereof.\n- (B) An internet website, online service, online application, or mobile application that operates a feed for the primary purpose of cloud storage.\n- (c) 'Media' means text, audio, an image, or a video.\n- (d) 'Minor' means an individual under 18 years of age who is located in the State of California.\n- (e) 'Operator' means a person who operates or provides an internet website, an online service, an online application, or a mobile application.\n- (f) 'Parent' means a parent or guardian, including as defined in regulations promulgated pursuant to this chapter.\n- (g) 'User' means a person who uses an internet website, online service, online application, or mobile application. 'User' does not include the operator or a person acting as an agent of the operator.", "metadata": {"h2": "CHAPTER 24. Protecting Our Kids from Social Media Addiction Act", "source_path": "data/kb_raw/California state law.txt", "h1": "", "h3": "", "law_name": "Protecting Our Kids from Social Media Addiction Act", "region": "US-CA", "article_or_section": "", "source": "https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240SB976"}}
{"id": "ca541eb5-7c4a-4886-8528-cf216ba05dbe", "text": "- (f) 'Parent' means a parent or guardian, including as defined in regulations promulgated pursuant to this chapter.\n- (g) 'User' means a person who uses an internet website, online service, online application, or mobile application. 'User' does not include the operator or a person acting as an agent of the operator.\n- 27001. (a) It shall be unlawful for the operator of an addictive internet-based service or application to provide an addictive feed to a user unless either of the following is met:\n- (1) (A) Except as provided in subparagraph (B), the operator does not have actual knowledge that the user is a minor.\n- (B) Commencing January 1, 2027, the operator has reasonably determined that the user is not a minor, including pursuant to regulations promulgated by the Attorney General.\n- (2) The operator has obtained verifiable parental consent to provide an addictive feed to the user who is a minor.\n- (b) Information collected for the purpose of determining a user's age or verifying parental consent pursuant to this chapter shall not be used for any purpose other than compliance with this chapter or with another applicable law. The information collected shall be deleted immediately after it is used to determine a user's age or to verify parental consent, except as necessary to comply with state or federal law.\n- 27002. (a) (1) Except as provided in paragraph (2), it shall be unlawful for the operator of an addictive internetbased service or application, between the hours of 12 a.m. and 6 a.m., in the user's local time zone, and between the hours of 8 a.m. and 3 p.m., from Monday through Friday from September through May in the user's local time zone, to send notifications to a user if the operator has actual knowledge that the user is a minor unless the operator has obtained verifiable parental consent to send those notifications.\n- (2) Commencing January 1, 2027, it shall be unlawful for the operator of an addictive internet-based service or application, between the hours of 12 a.m. and 6 a.m., in the user's local time zone, and between the hours of 8 a.m. and 3 p.m., from Monday through Friday from September through May in the user's local time zone, to send notifications to a user whom the operator has not reasonably determined is not a minor, including pursuant to regulations promulgated by the Attorney General, unless the operator has obtained verifiable parental consent to send those notifications.\n- (b) The operator of an addictive internet-based service or application shall provide a mechanism through which the verified parent of a user who is a minor may do any of the following:\n- (1) Prevent their child from accessing or receiving notifications from the addictive internet-based service or application between specific hours chosen by the parent. This setting shall be set by the operator as on by default, in a manner in which the child's access is limited between the hours of 12 a.m. and 6 a.m., in the user's local time zone.\n- (2) Limit their child's access to any addictive feed from the addictive internet-based service or application to a length of time per day specified by the verified parent. This setting shall be set by the operator as on by default, in a manner in which the child's access is limited to one hour per day unless modified by the verified parent.\n- (3) Limit their child's ability to view the number of likes or other forms of feedback to pieces of media within an addictive feed. This setting shall be set by the operator as on by default.\n- (4) Require that the default feed provided to the child when entering the internet-based service or application be one in which pieces of media are not recommended, selected, or prioritized for display based on information provided by the user, or otherwise associated with the user or the user's device, other than the user's age or status as a minor.", "metadata": {"h2": "CHAPTER 24. Protecting Our Kids from Social Media Addiction Act", "source_path": "data/kb_raw/California state law.txt", "h1": "", "h3": "", "law_name": "Protecting Our Kids from Social Media Addiction Act", "region": "US-CA", "article_or_section": "", "source": "https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240SB976"}}
{"id": "761e779e-558d-44a2-b229-9ddc40a8c24c", "text": "- (5) Set their child's account to private mode, in a manner in which only users to whom the child is connected on the addictive internet-based service or application may view or respond to content posted by the child. This setting shall be set by the operator as on by default.\n- 27003. (a) This chapter shall not be construed as requiring the operator of an addictive internet-based service or application to give a parent any additional or special access to, or control over, the data or accounts of their child.\n- (b) This chapter shall not be construed as preventing any action taken in good faith to restrict access to, or availability of, media.\n- 27004. (a) An operator may choose not to provide services to minors. However, the operator of an addictive internet-based service or application shall not withhold, degrade, lower the quality of, or increase the price of, any product, service, or feature, other than as required by this chapter, due to a user or parent availing themselves of the rights provided by this chapter, or due to the protections required by this chapter.\n- (b) A parent's provision of consent as described in Section 27001 or 27002, or the use by a parent of a mechanism as described in Section 27002, does not waive, release, otherwise limit, or serve as a defense to, any claim that the parent, or that the user who is a minor or was a minor at the time of using the internet-based service or application, might have against the operator of an addictive internet-based service or application regarding any harm to the mental health or well-being of the user.\n- (c) The protections provided by this chapter are in addition to those provided by any other applicable law, including, but not limited to, the California Age-Appropriate Design Code Act (Title 1.81.47 (commencing with Section 1798.99.28) of Part 4 of Division 3 of the Civil Code).\n- 27005. An operator of an addictive internet-based service or application shall publicly disclose, on an annual basis, the number of minor users of its addictive internet-based service or application, and of that total the number for whom the operator has received verifiable parental consent to provide an addictive feed, and the number of minor users as to whom the controls set forth in Section 27002 are or are not enabled.\n- 27006. (a) This chapter may only be enforced in a civil action brought in the name of the people of the State of California by the Attorney General.\n- (b) The Attorney General shall adopt regulations to further the purposes of this chapter, including regulations regarding age assurance and parental consent by January 1, 2027. The Attorney General may adopt regulations that provide for exceptions to this chapter, but only if those exceptions further the purpose of protecting minors.\n- (c) In promulgating the regulations described in subdivision (b), the Attorney General shall solicit public comment regarding the impact that any regulation might have based on the nondiscrimination characteristics set forth in Section 51 of the Civil Code or in any other applicable law.  \n27007. If any provision of this chapter, or application thereof, to any person or circumstance is held invalid, that invalidity shall not affect other provisions or applications of this chapter that can be given effect without the invalid provision or application, and to this end the provisions of this chapter are declared to be severable.", "metadata": {"h2": "CHAPTER 24. Protecting Our Kids from Social Media Addiction Act", "source_path": "data/kb_raw/California state law.txt", "h1": "", "h3": "", "law_name": "Protecting Our Kids from Social Media Addiction Act", "region": "US-CA", "article_or_section": "", "source": "https://leginfo.legislature.ca.gov/faces/billNavClient.xhtml?bill_id=202320240SB976"}}
{"id": "4b1cf1af-d534-4029-a4ec-15a4c69c61b7", "text": "## Digital Services Act  \nThe Digital Services Act [1] ( DSA ) is an EU regulation adopted in 2022 that addresses illegal content, transparent advertising and disinformation. It updates the Electronic Commerce Directive 2000 in EU law, [2][3] and was proposed alongside the Digital Markets Act (DMA).  \nThe DSA applies to online platforms and intermediaries such as social networks, marketplaces, pornographic platforms, [4] and app stores. [5] Key requirements include disclosing to regulators how their algorithms work, providing users with explanations for content moderation decisions, and implementing stricter controls on targeted advertising. It also imposes specific rules on \"very large\" online platforms and search engines (those having more than 45 million monthly active users in the EU). [6]", "metadata": {"h2": "Digital Services Act", "source_path": "data/kb_raw/EU Digital Service Act.txt", "h1": "", "h3": "", "law_name": "Digital Services Act", "region": "EU", "article_or_section": "", "source": "https://eur-lex.europa.eu/eli/reg/2022/2065/oj"}}
{"id": "98c54d43-3b4f-45b1-9799-d43d3f6ee7cf", "text": "## Objectives  \nUrsula von der Leyen proposed a \"new Digital Services Act\" in her 2019 bid for the European Commission's presidency. [7]  \nThe expressed purpose of the DSA was to update the European Union's legal framework for illegal content on intermediaries, in particular by modernising the e-Commerce Directive that had been adopted in 2000. In doing so, the DSA aimed to harmonise different national laws in the European Union that have emerged to address illegal content at national level. [2] Most prominent amongst these laws was the German NetzDG, and similar laws in Austria (\"KommunikationsplattformenGesetz\") and France (\"Loi Avia\"). With the adoption of the Digital Services Act at European level, those national laws were planned to be overridden and would have to be amended. [8]  \nIn practice, this would lead to new legislation regarding illegal content, transparent advertising and disinformation. [3]", "metadata": {"h2": "Objectives", "source_path": "data/kb_raw/EU Digital Service Act.txt", "h1": "", "h3": "", "law_name": "Digital Services Act", "region": "EU", "article_or_section": "", "source": "https://eur-lex.europa.eu/eli/reg/2022/2065/oj"}}
{"id": "848db8c3-a34a-42d1-8ff2-6999595f033f", "text": "## New obligations on platform companies\nThe DSA is meant to \"govern the content moderation practices of social media platforms\" and address illegal content. [9] It is organised in five chapters, with the most important chapters regulating the liability exemption of intermediaries (Chapter 2), the obligations on intermediaries (Chapter 3), and the cooperation and enforcement framework between the commission and national authorities (Chapter 4).  \nThe DSA proposal maintains the current rule according to which companies that host others' data become liable when informed that this data is illegal. [9] This so-called \"conditional liability exemption\" is fundamentally different [10][11] from the broad immunities given to intermediaries under the equivalent rule (\"Section 230 CDA\") in the United States.  \nThe DSA applies to intermediary service providers that offer their services to users based in the European Union, irrespective of whether the intermediary service provider is established in the European Union. [12]  \nIn addition to the liability exemptions, the DSA would introduce a wide-ranging set of new obligations on platforms, including some that aim to disclose to regulators how their algorithms work, while other obligations would create transparency on how decisions to remove content are taken and on the way advertisers target users. The European Centre for Algorithmic Transparency was created to aid the enforcement of this. [13]  \nA December 2020 Time article said that while many of its provisions only apply to platforms which have more than 45 million users in the European Union, the Act could have repercussions beyond Europe. Platforms including Facebook, Twitter, TikTok, and Google's subsidiary YouTube would meet that threshold and be subjected to the new obligations. [14]  \nA 16 November 2021 Internet Policy Review listed some of new obligations including mandatory \"notice-and-action\" requirements, for example, respect fundamental rights, mandatory redress for content removal decisions, and a comprehensive risk management and audit framework. [15]  \nCompanies that do not comply with the new obligations risk fines of up to 6% on their global annual turnover. In addition, the Commission can apply periodic penalties up to 5% of the average daily worldwide turnover for each day of delay in complying with remedies, interim measures, and commitments. As a last resort measure, if the infringement persists and causes serious harm to users and entails criminal offences involving threat to persons' life or safety, the Commission can request the temporary suspension of the service. [16]", "metadata": {"h2": "New obligations on platform companies", "source_path": "data/kb_raw/EU Digital Service Act.txt", "h1": "", "h3": "", "law_name": "Digital Services Act", "region": "EU", "article_or_section": "", "source": "https://eur-lex.europa.eu/eli/reg/2022/2065/oj"}}
{"id": "7b1e6c8e-0d80-40ba-a560-88d4e5aa2b6b", "text": "## Large online platforms\nOn 23 April 2023, the European Commission named a first list of 19 online platforms that will be required to comply starting 25 August 2023. [17] They include the following very large online platforms (VLOPs) with more than 45 million monthly active users in the EU as of 17 February 2023. [18]  \n- Alibaba AliExpress\n- Amazon Store\n- Apple AppStore\n- Booking.com\n- Facebook\n- Google Play\n- Google Maps\n- Google Shopping\n- Instagram\n- LinkedIn\n- Pinterest\n- PornHub (added 20 December 2023)\n- Shein (added 26 April 2024)\n- Snapchat\n- Stripchat (added 20 December 2023)\n- Temu (added 31 May 2024)\n- TikTok\n- Wikipedia\n- X (formerly Twitter)\n- XNXX (added 10 July 2024)\n- XVideos (added 20 December 2023)\n- YouTube\n- Zalando  \nVery Large Online Search Engines (VLOSEs):\n- Bing\n- Google Search  \nAmazon and Zalando both initiated proceedings in the General Court challenging the designations, claiming unequal treatment compared to other large retailers, and that their core business models are retail not distributing third party content/products. Zalando argued the criteria and methodology lack transparency, for instance in how it counts active users, while Amazon said VLOP rules are disproportionate for its business model and asked to be exempted from transparency around targeted ads. [19][20]  \nAs of December 2023, 13 VLOPs have received a request for information (RFI), [16] the procedure necessary to verify compliance with the DSA, and one is being subjected to a formal proceedings. [21] 3 further platforms, all of them providing adult content, were added on 20 December 2023. [22]", "metadata": {"h2": "Large online platforms", "source_path": "data/kb_raw/EU Digital Service Act.txt", "h1": "", "h3": "", "law_name": "Digital Services Act", "region": "EU", "article_or_section": "", "source": "https://eur-lex.europa.eu/eli/reg/2022/2065/oj"}}
{"id": "a6d7e86d-bc91-49d3-a381-41215fbe950c", "text": "## Legislative history  \nThe European Commission submitted the DSA alongside the Digital Markets Act (DMA) to the European Parliament and the Council on 15 December 2020. [5][23] The DSA was prepared by von der Leyen Commission members Margrethe Vestager (Executive Vice President of the European Commission for A Europe Fit for the Digital Age) and Thierry Breton (European Commissioner for Internal Market). [24]  \nThe Digital Services Act builds in large parts on the non-binding Commission Recommendation 2018/314 of 1 March 2018 [25] when it comes to illegal content on platforms. However, it goes further in addressing topics such as disinformation and other risks especially on very large online platforms. As part of the preparatory phase, the European Commission launched a public consultation on the package to gather evidence between July and September 2020. [26][27] An impact assessment was published alongside the proposal on 15 December 2020 with the relevant evidence base. [28]  \nThe European Parliament appointed Danish Social Democrat Christel Schaldemose as rapporteur for the Digital Services Act. On 20 January 2022 the Parliament voted to introduce amendments in the DSA for tracking-free advertising and a ban on using a minor's data for targeted ads, as well as a new right for users to seek compensation for damages. [29] In the wake of the Facebook Files revelations and a hearing by Facebook Whistleblower Frances Haugen in the European Parliament, [30] the European Parliament also strengthened the rules on fighting disinformation and harmful content, as well as tougher auditing requirements. [31]  \nThe Council of the European Union adopted its position on 25 November 2021. [32] The most significant changes introduced by the Member States are to entrust the European Commission with the enforcement of the new rules, in the wake of allegations and complaints that the Irish Data Protection Watchdog was not effectively policing the bloc's data protection rules against platform companies. [33]  \nThe Data Governance Act (DGA) was formally approved by the European Parliament on 6 April 2022. [34] This sets up a legal framework for common data spaces in Europe which will increase data sharing in sectors such as finance, health, and the environment. [34][35]  \nWith Russia using social media platforms to spread misinformation about the 2022 Russian invasion of Ukraine, European policymakers felt a greater sense of urgency to move the legislation forward to ensure that major tech platforms were transparent and properly regulated, according to The Washington Post . [36] On 22 April 2022, the Council of the European Union and the European Parliament reached a deal on the Digital Services Act in Brussels following sixteen hours of negotiations. [37][38][39] According to The Washington Post , the agreement reached in Brussels solidifies the two-bill plan- the Digital Services Act and the Digital Markets Act, a law regulating competition. The latter is aimed at preventing abuse of power against smaller competitors by larger \"gatekeepers\". [36]  \nOn 5 July 2022, the European Parliament approved both the DSA and the DMA. [40] Following this, on 4 October 2022, the European Council gave its final approval to the DSA. [41] The DSA was adopted on 19 October 2022 and was published in the Official Journal of the European Union on 27 October 2022. [1] It came into force on 16 November 2022. [42] Most services were given 15 months to comply with its provisions (until 17 February 2024 [43] ). However, \"very large\" online platforms and search engines, after their designation as such, had only four months to comply (until 23 August 2023). [40]", "metadata": {"h2": "Legislative history", "source_path": "data/kb_raw/EU Digital Service Act.txt", "h1": "", "h3": "", "law_name": "Digital Services Act", "region": "EU", "article_or_section": "", "source": "https://eur-lex.europa.eu/eli/reg/2022/2065/oj"}}
{"id": "42e0ce1d-81cc-45b0-9d4b-9ccbfbacf978", "text": "## Influence of the European Court of Human Rights  \nThe DSA was passed alongside the Digital Markets Act and the Democracy Action Plan. [44] The latter of these is focused on addressing the nuanced legal interpretation of free speech on digital platforms, a fundamental right that has been extensively guided by the European Court of Human Rights (ECtHR) and the European Convention on Human Rights. [45] Accordingly, the Democracy  \nAction Plan, and subsequently the DSA, were strongly influenced by the Delfi AS v. Estonia and Magyar Tartalomszolgáltatók Egyesülete and Index.hu Zrt v. Hungary ECtHR cases, which outlined a framework for assessing intermediary liability on digital platforms. [46]  \nIn Delfi AS v. Estonia , the ECtHR applied proportionality analysis when considering whether the Estonian courts' decision to hold the online platform Delfi liable for hate speech posted by its users was a proportionate restriction on Delfi's right to freedom of expression. [47] The court found that, given the serious nature of the hate speech, the Estonian courts' actions were justified to protect the rights of others. [48] In other words, the ECtHR upheld the liability of online platforms for hate speech posted by their users, underlining that platforms could be expected to take proactive steps to control content when there is a clear risk of harm from unlawful comments. This case highlighted the responsibilities of platforms to prevent the spread of harmful content. [47]  \nOn the other hand, the MTE and Index.hu v. Hungary case illustrated the nuanced limits of freedom of speech on digital platforms. [49] In its application of proportionality analysis, the ECtHR found that the Hungarian courts had failed to strike a fair balance between protecting reputation and ensuring freedom of expression. [50] The Hungarian courts imposed strict liability on the platforms for user comments that were offensive but did not constitute hate speech, constituting a disproportionate interference in the platforms' right to freedom of expression. The ECtHR ruled that imposing strict liability on platforms for user comments, without consideration of the nature of the comments or the context in which they were made, could infringe on freedom of expression. This judgment emphasized the need for a balance between protecting reputation and upholding free speech on digital platforms. [49]  \nThese decisions by the ECtHR provided critical legal precedents that shaped the EU's decisionmaking process on the framework of the DSA. In particular, the DSA drew from the ECtHR's distinction between different types of illegal content, as well as its proportionality analysis in both cases, by incorporating nuanced rules on intermediary liability and ensuring that measures taken by platforms do not unreasonably restrict users' freedom of expression and information. [51]", "metadata": {"h2": "Influence of the European Court of Human Rights", "source_path": "data/kb_raw/EU Digital Service Act.txt", "h1": "", "h3": "", "law_name": "Digital Services Act", "region": "EU", "article_or_section": "", "source": "https://eur-lex.europa.eu/eli/reg/2022/2065/oj"}}
{"id": "064e6d6a-1df9-4dbd-baa5-e2a4761c182d", "text": "## Reactions  \nMedia reactions to the Digital Services Act have been mixed. In January 2022, the editorial board of The Washington Post stated that the U.S. could learn from these rules, [52] while whistleblower Frances Haugen stated that it could set a \"gold standard\" of regulation worldwide. [53] Tech journalist Casey Newton has argued that the DSA will shape US tech policy. [54] Mike Masnick of Techdirt praised the DSA for ensuring the right to pay for digital services anonymously, but criticised the act for not including provisions that would have required a court order for the removal of illegal content. [55]  \nScholars have begun critically examining the Digital Services Act. [56][57] Some academics have expressed concerns that the Digital Services Act might be too rigid and prescribed, [58] excessively focused on individual content decisions or vague risk assessments. [59]  \nCivil Society organisations such as Electronic Frontier Foundation have called for stronger privacy protections. [60] Human Rights Watch has welcomed the transparency and user remedies but called for an end to abusive surveillance and profiling. [61] Amnesty International has welcomed many aspects of the proposal in terms of fundamental rights balance, but also asked for further restrictions on advertising. [62] Advocacy organisation Avaaz has compared the Digital Services Act to the Paris Agreement for climate change. [63]  \nFollowing the 2023 Hamas-led attack on Israel, Thierry Breton wrote public letters to X, Meta Platforms, TikTok, and YouTube on how their platforms complied with the DSA regarding content related to the conflict and upcoming elections. The Atlantic Council's Digital Forensic Research Lab reported that Breton's letters did not follow DSA processes, and digital rights group Access Now criticised Breton's letters for drawing a \"false equivalence\" between illegal content and disinformation. [64]  \nTech companies have repeatedly criticised the heavy burden of the rules and the alleged lack of clarity of the Digital Services Act, [65] and have been accused of lobbying to undermine some of the more far-reaching demands by law-makers, notably on bans for targeted advertising, [66] and a high-profile apology from Sundar Pichai to Breton on leaked plans by Google to lobby against the Digital Services Act. [67]  \nA bipartisan group of US senators have called the DSA and DMA discriminatory, claiming that the legislation would \"focus on regulations on a handful of American companies while failing to regulate similar companies based in Europe, China, Russia and elsewhere.\" [68][69]  \nThe DSA was mostly welcomed by the European media sector. [70] Due to the influence gatekeepers have in selecting and controlling the visibility of certain journalistic articles over others through their online platforms, the European Federation of Journalists encouraged EU legislators to further increase the transparency of platforms' recommendation systems via the DSA. [71]  \nNevertheless, the DSA's later stage inter-institutional negotiations, or trilogues, have been criticized as lacking transparency and equitable participation. [72] These criticisms mirror past experiences with the drafting of the EU Regulation on Preventing the Dissemination of Terrorist Content Online as well as the General Data Protection Regulation (GDPR). [73]  \nSwedish member of the European Parliament Jessica Stegrud argued that the DSA's focus on preventing the spread of disinformation and \"harmful content\" would undermine freedom of speech. [74]  \nAfter the first round of the 2024 Romanian presidential election was invalidated due to reports allegedly showing Russian involvement on TikTok in favor of Călin Georgescu, an investigation was conducted to determine whether TikTok had breached the DSA. [75]", "metadata": {"h2": "Reactions", "source_path": "data/kb_raw/EU Digital Service Act.txt", "h1": "", "h3": "", "law_name": "Digital Services Act", "region": "EU", "article_or_section": "", "source": "https://eur-lex.europa.eu/eli/reg/2022/2065/oj"}}
{"id": "1b02b84e-f399-4127-8a38-faa5b1ba01e0", "text": "## Impacts", "metadata": {"h2": "Impacts", "source_path": "data/kb_raw/EU Digital Service Act.txt", "h1": "", "h3": "", "law_name": "Digital Services Act", "region": "EU", "article_or_section": "", "source": "https://eur-lex.europa.eu/eli/reg/2022/2065/oj"}}
{"id": "714ddda7-d076-48a3-afa3-13447225a9fe", "text": "## Feature and content removal  \nIn August 2024, TikTok agreed to withdraw its TikTok Lite rewards feature after it was investigated under the DSA due to concerns about its \"addictive effect\", especially for children. [76][77]  \nA 2024 study of deleted Facebook and YouTube comments by the Future of Free Speech think tank at Vanderbilt University suggested that \"platforms, pages, or channels may be over-removing content to avoid regulatory penalties\" under the DSA. [78]", "metadata": {"h2": "Feature and content removal", "source_path": "data/kb_raw/EU Digital Service Act.txt", "h1": "", "h3": "", "law_name": "Digital Services Act", "region": "EU", "article_or_section": "", "source": "https://eur-lex.europa.eu/eli/reg/2022/2065/oj"}}
{"id": "cf2503c4-f04d-4e00-bf20-9090dbbcb65a", "text": "## Outside the EU  \nThe Washington Post wrote in 2023 that tech companies may apply features instituted to comply with the DSA to countries outside of the EU, and that researchers have argued that the DSA could provide a framework for the United States to impose stricter regulations on tech companies. [79] The Economist wrote in 2023 that the Brussels effect, whereby social media platforms implement EU regulations globally to save costs, \"is far from guaranteed\" with the DSA due to tech companies being unwilling to \"[lose] sovereignty over their digital territories everywhere\". [80]  \nAmong legal academics, Dawn Nunziato of the George Washington University argued in 2022 that the DSA \"will further instantiate the Brussels Effect, whereby EU regulators wield powerful influence on how social media platforms moderate content on the global scale\". [81] Suzanne Vergnolle of the Conservatoire national des arts et métiers stated her belief in 2023 that the DSA would have a Brussels effect, similar to that of the General Data Protection Regulation, but that \"it's going to take years\". [82] Martin Husovec of the London School of Economics and Jennifer Urban of the University of California, Berkeley wrote in 2024 that \"the chances of spontaneous voluntary implementation beyond the EU's borders for four key parts of the DSA - content moderation procedures, transparency and governance obligations, and risk management rules seem modest.\" [83]", "metadata": {"h2": "Outside the EU", "source_path": "data/kb_raw/EU Digital Service Act.txt", "h1": "", "h3": "", "law_name": "Digital Services Act", "region": "EU", "article_or_section": "", "source": "https://eur-lex.europa.eu/eli/reg/2022/2065/oj"}}
{"id": "953c85a6-38ae-4b92-8528-f9005bd9dfaf", "text": "## Similar legislation  \nThe 2023 Brazilian Fake News Bill, a proposed new social media regulation framework introduced in the National Congress, heavily referenced the DSA and contained similar provisions. [84][85]", "metadata": {"h2": "Similar legislation", "source_path": "data/kb_raw/EU Digital Service Act.txt", "h1": "", "h3": "", "law_name": "Digital Services Act", "region": "EU", "article_or_section": "", "source": "https://eur-lex.europa.eu/eli/reg/2022/2065/oj"}}
{"id": "50577329-96c4-4603-aff8-843ab51fb9a9", "text": "## See also  \n- Digital Markets Act\n- Trade and Technology Council\n- Big Tech\n- Platform economy\n- Online Streaming Act\n- WeChat\n- Transparency and targeting of political advertising", "metadata": {"h2": "See also", "source_path": "data/kb_raw/EU Digital Service Act.txt", "h1": "", "h3": "", "law_name": "Digital Services Act", "region": "EU", "article_or_section": "", "source": "https://eur-lex.europa.eu/eli/reg/2022/2065/oj"}}
{"id": "54afa7b8-601d-4560-8a96-ab6ff8484e62", "text": "## External links  \n- \"The Digital Services Act\" (https://ec.europa.eu/info/digital-services-act-ensuring-safe-and-acco untable-online-environment\\_en). European Commission . 27 October 2022.\n- \"Infographics - Digital Services Act\" (https://www.consilium.europa.eu/en/infographics/digital-s ervices-act/). 30 September 2022. Retrieved 12 January 2025.\n- Regulation (EU) 2022/2065 of the European Parliament and of the Council of 19 October 2022 on a Single Market For Digital Services and amending Directive 2000/31/EC (Digital Services Act) (https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX:32022R2065)\n- COM (2020) 825: Proposal for a REGULATION OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL on a Single Market For Digital Services (Digital Services Act) and amending Directive 2000/31/EC (https://eur-lex.europa.eu/legal-content/EN/HIS/?uri=CELEX:32022R206 5)\n- \"Procedure 2020/0361(COD)\" (https://oeil.secure.europarl.europa.eu/oeil/popups/ficheprocedu re.do?reference=2020/0361(COD)&amp;l=en). ŒIL .", "metadata": {"h2": "External links", "source_path": "data/kb_raw/EU Digital Service Act.txt", "h1": "", "h3": "", "law_name": "Digital Services Act", "region": "EU", "article_or_section": "", "source": "https://eur-lex.europa.eu/eli/reg/2022/2065/oj"}}
{"id": "dcdc5139-5823-4411-b6c6-e1eda8e51c65", "text": "## The Florida Senate", "metadata": {"h2": "The Florida Senate", "source_path": "data/kb_raw/Florida state law.txt", "h1": "", "h3": "", "law_name": "Online Protections for Minors", "region": "US-FL", "article_or_section": "", "source": "https://www.flsenate.gov/Session/Bill/2024/3"}}
{"id": "27dde290-8dbe-4d84-aa36-e466087f4efb", "text": "## CS/CS/HB 3: Online Protections for Minors  \nGENERAL BILL by Judiciary Committee ; Regulatory Reform &amp; Economic Development Subcommittee ; Tramont ; Overdorf ; Sirois ; McFarland ; Rayner ; (CO-INTRODUCERS) Anderson ; Bankson ; Barnaby ; Beltran ; Black ; Botana ; Brackett ; Buchanan ; Canady ; Caruso ; Chamberlin ; Chambliss ; Chaney ; Fabricio ; Garcia ; Gonzalez Pittman ; Gossett-Seidman ; Gregory ; Jacques ; Leek ; Lopez, V. ; Massullo ; McClain ; Melo ; Michael ; Mooney ; Payne ; Persons-Mulicka ; Plakon ; Plasencia ; Roth ; Salzman ; Snyder ; Steele ; Temple ; Trabulsy ; Truenow ; Tuck ; Waldron ; Yarkosky ; Yeager  \nOnline Protections for Minors; Requiring social media platforms to prohibit certain minors from creating new accounts; requiring social media platforms to terminate certain accounts and provide additional options for termination of such accounts; providing conditions under which social media platforms are required to prohibit certain minors from entering into contracts to become account holders; authorizing the Department of Legal Affairs to bring actions under the Florida Deceptive and Unfair Trade Practices Act for knowing or reckless violations; authorizing the department to issue and enforce civil investigative demands under certain circumstances, etc.  \nEffective Date:  \n1/1/2025  \nLast Action:  \n3/25/2024 - Chapter No. 2024-42; companion  \nbill(s) passed, see CS/CS/HB 1491 (Ch. 2024-54)  \nBill Text:  \nPDF", "metadata": {"h2": "CS/CS/HB 3: Online Protections for Minors", "source_path": "data/kb_raw/Florida state law.txt", "h1": "", "h3": "", "law_name": "Online Protections for Minors", "region": "US-FL", "article_or_section": "", "source": "https://www.flsenate.gov/Session/Bill/2024/3"}}
{"id": "0a22fdb7-9fa8-4bae-905f-f8c8f7d6fc52", "text": "## BILL HISTORY  \n| Date | Chamber | Action |\n|-----------|-----------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n| 1/5/2024 | House | • Filed |\n| 1/9/2024 | House | • Referred to Regulatory Reform &Economic Development Subcommittee • Referred to Judiciary Committee • Now in Regulatory Reform &Economic Development Subcommittee • Added to Regulatory Reform &Economic Development Subcommittee agenda • 1st Reading (Original Filed Version) |\n| 1/11/2024 | House | • Favorable with CS by Regulatory Reform &Economic Development Subcommittee • Reported out of Regulatory Reform &Economic Development Subcommittee • Laid on Table under Rule 7.18(a) • CS Filed • 1st Reading (Committee Substitute 1) |\n| 1/12/2024 | House | • Referred to Judiciary Committee • Now in Judiciary Committee • Added to Judiciary Committee agenda |\n| 1/17/2024 | House | • Favorable with CS by Judiciary Committee • Reported out of Judiciary Committee |\n| 1/18/2024 | House | • Laid on Table under Rule 7.18(a) • CS Filed • Bill referred to House Calendar • Bill added to Special Order Calendar (1/23/2024) • 1st Reading (Committee Substitute 2) |\n| 1/23/2024 | House | • Read 2nd time • Placed on 3rd reading • Added to Third Reading Calendar\n| |\n| 1/24/2024 | House | • Read 3rd time • CS passed; YEAS 119, NAYS 0 |\n| 1/24/2024 | Senate | • In Messages |\n| 1/25/2024 | Senate | • Referred to Fiscal Policy • Received |\n| 2/12/2024 | Senate | • On Committee agenda-- Fiscal Policy, 02/15/24, 12:00 pm, 412 Knott Building --Temporarily Postponed |\n| 2/15/2024 | Senate | • Placed on Special Order Calendar, 02/21/24 --If Received |\n| 3/1/2024 | Senate | • Withdrawn from Fiscal Policy -SJ 575 • Placed on Calendar, on 2nd reading • Placed on Special Order Calendar, 03/04/24 -SJ 575 |\n| 3/4/2024 | Senate | • Read 2nd time -SJ 622 • Amendment(s) adopted (961382) -SJ 622 • Read 3rd time -SJ 625 • CS passed as amended; YEAS 30 NAYS 5 -SJ 625 |\n| 3/4/2024 | House | • In Messages |\n| 3/6/2024 | House | • Added to Senate Message List • Amendment 961382 Concur • CS passed as amended; YEAS 109, NAYS 4 • Ordered engrossed, then enrolled |\n| 3/21/2024 | | • Signed by Officers and presented to Governor |\n| 3/25/2024 | | • Approved by Governor • Chapter No. 2024-42; companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-54) |", "metadata": {"h2": "BILL HISTORY", "source_path": "data/kb_raw/Florida state law.txt", "h1": "", "h3": "", "law_name": "Online Protections for Minors", "region": "US-FL", "article_or_section": "", "source": "https://www.flsenate.gov/Session/Bill/2024/3"}}
{"id": "58c78f5e-8f1b-411a-8b48-84769f9cb633", "text": "## POSTED 3/7/2024 AT 10:14 AM CS/CS/HB 3, ENROLLED (CURRENT BILL VERSION)", "metadata": {"h2": "POSTED 3/7/2024 AT 10:14 AM CS/CS/HB 3, ENROLLED (CURRENT BILL VERSION)", "source_path": "data/kb_raw/Florida state law.txt", "h1": "", "h3": "", "law_name": "Online Protections for Minors", "region": "US-FL", "article_or_section": "", "source": "https://www.flsenate.gov/Session/Bill/2024/3"}}
{"id": "24e4dcbb-3e94-46ec-8a75-633ad5da1ba0", "text": "## Related Bills (6)  \n| Bill Number | Subject | Filed By | Relationship | Last Action and Location | Track Bills |\n|---------------|-------------------------------------------------------------|-------------------------------------------------------|----------------|---------------------------------------------------------------------------------------------------|---------------|\n| H1491 (er) | Pub. Rec./Investigations by the Department of Legal Affairs | Regulatory Reform & Economic Development Subcommittee | Linked | Last Action: 4/3/2024 Chapter No. 2024-54; companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) | |\n| H1 (er) | Online Protections for Minors | Judiciary Committee | Similar | Last Action: 3/1/2024 Vetoed by Governor; companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42); companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-2024-54) | |\n| H1377 (er) | Pub. Rec./Investigations by the Department of Legal Affairs | State Affairs Committee | Compare | Last Action: 3/1/2024 Vetoed by Governor; companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-54), CS/CS/HB 3 (Ch. | |\n| S 454 | Protection of Minors on Social Media Platforms | Garcia | Compare | Last Action: 3/8/2024 S Died in Commerce and Tourism, companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) | |\n| S 1788 (c1) | Social Media Use for Minors | Grall | Compare | Last Action: 3/8/2024 S Died in Fiscal Policy, companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) | |\n| S 1792 (c1) | Online Access to Materials Harmful to Minors | Grall | Compare | Last Action: 3/8/2024 S Died in Fiscal Policy, companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) | |", "metadata": {"h2": "Related Bills (6)", "source_path": "data/kb_raw/Florida state law.txt", "h1": "", "h3": "", "law_name": "Online Protections for Minors", "region": "US-FL", "article_or_section": "", "source": "https://www.flsenate.gov/Session/Bill/2024/3"}}
{"id": "35fb0b23-210d-4d86-876a-ae09d6911657", "text": "## Citations - Statutes (3)  \n| Citation | Catchline | Location in Bill Location In Bill Help |\n|------------|-------------|------------------------------------------|\n| 501.174 | | Page 3 (PDF) |\n| 501.174 | | Page 12 (PDF) |\n| 501.174 | | Page 19 (PDF) |", "metadata": {"h2": "Citations - Statutes (3)", "source_path": "data/kb_raw/Florida state law.txt", "h1": "", "h3": "", "law_name": "Online Protections for Minors", "region": "US-FL", "article_or_section": "", "source": "https://www.flsenate.gov/Session/Bill/2024/3"}}
{"id": "075167f8-062c-4398-a7f3-fb172993924f", "text": "## CS/CS/HB 3, ENGROSSED 1", "metadata": {"h2": "CS/CS/HB 3, ENGROSSED 1", "source_path": "data/kb_raw/Florida state law.txt", "h1": "", "h3": "", "law_name": "Online Protections for Minors", "region": "US-FL", "article_or_section": "", "source": "https://www.flsenate.gov/Session/Bill/2024/3"}}
{"id": "ee8ae329-e9d1-429f-a303-c9ba7c69097f", "text": "## Related Bills (8)\n| Bill Number | Subject | Filed By | Relationship | Last Action and Location | Track Bills |\n|---------------|------------------------------------------------------------------|-------------------------------------------------------|----------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------|\n| H1491 (er) | Pub. Rec./Investigations by the Department of Legal Affairs | Regulatory Reform & Economic Development Subcommittee | Linked | Last Action: 4/3/2024 Chapter No. 2024-54; companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) | |\n| S 1792 (c1) | Online Access to Materials Harmful to Minors | Grall | Identical | Last Action: 3/8/2024 S Died in Fiscal Policy, companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) | |\n| H1 (er) | Online Protections for Minors | Judiciary Committee | Compare | Last Action: 3/1/2024 Vetoed by Governor; companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42); companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-2024-54) | |\n| H207 | Social Media Protection for Minors | Rayner, Sirois | Compare | Last Action: 3/8/2024 HDied on Second Reading Calendar | |\n| S 454 | Protection of Minors on Social Media Platforms | Garcia | Compare | Last Action: 3/8/2024 S Died in Commerce and Tourism, companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) | |\n| S 1430 | Social Media Protection for Minors | Book | Compare | Last Action: 3/8/2024 S Died in Judiciary | |\n| S 1788 (c1) | Social Media Use for Minors | Grall | Compare | Last Action: 3/8/2024 S Died in Fiscal Policy, companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) | |\n| S 1794 | Public Records/Investigations by the Department of Legal Affairs | Grall | Compare | Last Action: 3/8/2024 S Died in Fiscal Policy, companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-54) | |", "metadata": {"h2": "Related Bills (8)", "source_path": "data/kb_raw/Florida state law.txt", "h1": "", "h3": "", "law_name": "Online Protections for Minors", "region": "US-FL", "article_or_section": "", "source": "https://www.flsenate.gov/Session/Bill/2024/3"}}
{"id": "e1a2c1be-6361-4cc2-9b15-faf5b6ec7224", "text": "## Citations - Statutes (3)  \n| Citation | Catchline | Location in Bill Location In Bill Help |\n|------------|-------------|------------------------------------------|\n| 501.174 | | |\n| 501.174 | | Page 2 (PDF) |\n| 501.174 | | |", "metadata": {"h2": "Citations - Statutes (3)", "source_path": "data/kb_raw/Florida state law.txt", "h1": "", "h3": "", "law_name": "Online Protections for Minors", "region": "US-FL", "article_or_section": "", "source": "https://www.flsenate.gov/Session/Bill/2024/3"}}
{"id": "fe5403fa-6a66-4703-adca-81264d3a7235", "text": "## POSTED 1/18/2024 AT 8:48 AM CS/CS/HB 3, COMMITTEE SUBSTITUTE 2  \nAnalyses: Fiscal Policy (Pre-Meeting) 2/13/2024 (PDF)", "metadata": {"h2": "POSTED 1/18/2024 AT 8:48 AM CS/CS/HB 3, COMMITTEE SUBSTITUTE 2", "source_path": "data/kb_raw/Florida state law.txt", "h1": "", "h3": "", "law_name": "Online Protections for Minors", "region": "US-FL", "article_or_section": "", "source": "https://www.flsenate.gov/Session/Bill/2024/3"}}
{"id": "eebf86a2-fdca-4d33-adcc-669741677bdf", "text": "## Related Bills (8)  \n| Bill Number | Subject | Filed By | Relationship | Last Action and Location | Track Bills |\n|---------------|-------------------------------------------------------------|-------------------------------------------------------|----------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------|\n| H1491 (er) | Pub. Rec./Investigations by the Department of Legal Affairs | Regulatory Reform & Economic Development Subcommittee | Linked | Last Action: 4/3/2024 Chapter No. 2024-54; companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) | |\n| S 1792 (c1) | Online Access to Materials Harmful to Minors | Grall | Identical | Last Action: 3/8/2024 S Died in Fiscal Policy, companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) | |\n| H1 (er) | Online Protections for Minors | Judiciary Committee | Compare | Last Action: 3/1/2024 Vetoed by Governor; companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42); companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-2024-54) | |\n| H207 | Social Media Protection for Minors | Rayner, Sirois | Compare | Last Action: 3/8/2024 HDied on Second Reading Calendar | |\n| S 454 | Protection of Minors on Social Media Platforms | Garcia | Compare | Last Action: 3/8/2024 S Died in Commerce and Tourism, companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) | |\n| S 1430 | Social Media Protection for Minors | Book | Compare | Last Action: 3/8/2024 S Died in Judiciary | |\n| S 1788 (c1) | Social Media Use for Minors | Grall | Compare | Last Action: 3/8/2024 S Died in Fiscal Policy, companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) | |\n| S 1794 | Public Records/Investigations by the Department of Legal Affairs | Grall | Compare | Last Action: 3/8/2024 S Died in Fiscal Policy, companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-54) | |", "metadata": {"h2": "Related Bills (8)", "source_path": "data/kb_raw/Florida state law.txt", "h1": "", "h3": "", "law_name": "Online Protections for Minors", "region": "US-FL", "article_or_section": "", "source": "https://www.flsenate.gov/Session/Bill/2024/3"}}
{"id": "59667d90-1014-4714-9f8b-44dea97c72d6", "text": "## Committee Amendments (1)  \n| Amendment | Sponsor | Filed | Last Committee Action | Format |\n|-----------------------------------------------------------------------------------------|------------------------|--------------------|-------------------------|--------------|\n| 493094 - Amendment (Delete All) Delete everything after the enacting clause and insert: | Fiscal Policy (Hutson) | 2/14/2024 12:00 PM | | Web Page PDF |", "metadata": {"h2": "Committee Amendments (1)", "source_path": "data/kb_raw/Florida state law.txt", "h1": "", "h3": "", "law_name": "Online Protections for Minors", "region": "US-FL", "article_or_section": "", "source": "https://www.flsenate.gov/Session/Bill/2024/3"}}
{"id": "cb39358a-4433-4920-ae10-cc059f102ef8", "text": "## Floor Amendments (1)  \n| Amendment | Sponsor | Filed | Last Floor Action | Format |\n|-----------------------------------------------------------------------------------------|-----------|------------------|------------------------|--------------|\n| 961382 - Amendment (Delete All) Delete everything after the enacting clause and insert: | Grall | 3/1/2024 3:18 PM | House: Concur 3/6/2024 | Web Page PDF |", "metadata": {"h2": "Floor Amendments (1)", "source_path": "data/kb_raw/Florida state law.txt", "h1": "", "h3": "", "law_name": "Online Protections for Minors", "region": "US-FL", "article_or_section": "", "source": "https://www.flsenate.gov/Session/Bill/2024/3"}}
{"id": "8ee5e191-450b-4db5-8dcf-2559a8b5778c", "text": "## Floor Votes (3)  \n| Date | Chamber | Result |\n|-------------------|-----------|-------------------|\n| 1/24/2024 5:03 PM | House | 119 Yeas - 0 Nays |\n| 3/4/2024 10:28 AM | Senate | 30 Yeas - 5 Nays |\n| 3/6/2024 6:16 PM | House | 109 Yeas - 4 Nays |", "metadata": {"h2": "Floor Votes (3)", "source_path": "data/kb_raw/Florida state law.txt", "h1": "", "h3": "", "law_name": "Online Protections for Minors", "region": "US-FL", "article_or_section": "", "source": "https://www.flsenate.gov/Session/Bill/2024/3"}}
{"id": "c8f1b6b7-02d8-4818-a3fe-3f3fe7db5a74", "text": "## Citations - Statutes (1)  \n| Citation | Catchline | Location in Bill Location In Bill Help |\n|------------|-------------|------------------------------------------|\n| 501.174 | | Page 2 (PDF) |", "metadata": {"h2": "Citations - Statutes (1)", "source_path": "data/kb_raw/Florida state law.txt", "h1": "", "h3": "", "law_name": "Online Protections for Minors", "region": "US-FL", "article_or_section": "", "source": "https://www.flsenate.gov/Session/Bill/2024/3"}}
{"id": "7540f219-11c7-420b-a412-924694d1f32e", "text": "## CS/HB 3, COMMITTEE SUBSTITUTE 1", "metadata": {"h2": "CS/HB 3, COMMITTEE SUBSTITUTE 1", "source_path": "data/kb_raw/Florida state law.txt", "h1": "", "h3": "", "law_name": "Online Protections for Minors", "region": "US-FL", "article_or_section": "", "source": "https://www.flsenate.gov/Session/Bill/2024/3"}}
{"id": "54f77432-e404-4752-a44f-5790f7fcca4e", "text": "## Related Bills (8)  \n| Bill Number | Subject | Filed By | Relationship | Last Action and Location | Track Bills |\n|---------------|------------------------------------------------------------------|-------------------------------------------------------|----------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------|\n| H1491 (c1) | Pub. Rec./Investigations by the Department of Legal Affairs | Regulatory Reform & Economic Development Subcommittee | Linked | Last Action: 4/3/2024 Chapter No. 2024-54; companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) | |\n| S 1792 | Online Access to Materials Harmful to Minors | Grall | Similar | Last Action: 3/8/2024 S Died in Fiscal Policy, companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) | |\n| H1 (c1) | Social Media Use for Minors | Judiciary Committee | Compare | Last Action: 3/1/2024 Vetoed by Governor; companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42); companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-2024-54) | |\n| H207 | Social Media Protection for Minors | Rayner, Sirois | Compare | Last Action: 3/8/2024 HDied on Second Reading Calendar | |\n| S 454 | Protection of Minors on Social Media Platforms | Garcia | Compare | Last Action: 3/8/2024 S Died in Commerce and Tourism, companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) | |\n| S 1430 | Social Media Protection for Minors | Book | Compare | Last Action: 3/8/2024 S Died in Judiciary | |\n| S 1788 | Age Verification for Social Media Platform Accounts | Grall | Compare | Last Action: 3/8/2024 S Died in Fiscal Policy, companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) | |\n| S 1794 | Public Records/Investigations by the Department of Legal Affairs | Grall | Compare | Last Action: 3/8/2024 S Died in Fiscal Policy, companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-54) | |", "metadata": {"h2": "Related Bills (8)", "source_path": "data/kb_raw/Florida state law.txt", "h1": "", "h3": "", "law_name": "Online Protections for Minors", "region": "US-FL", "article_or_section": "", "source": "https://www.flsenate.gov/Session/Bill/2024/3"}}
{"id": "4262b1a9-7d30-4ef2-80e0-0aa0ddca669c", "text": "## Committee Amendments (1)\n| Amendment | Sponsor | Filed | Last Committee Action | Format |\n|---|---|---|---|---|\n| 901561 - Amendment Remove line 72 and insert: | Tramont | 1/16/2024 3:20 PM | Adopted 1/17/2024 | PDF |", "metadata": {"h2": "Committee Amendments (1)", "source_path": "data/kb_raw/Florida state law.txt", "h1": "", "h3": "", "law_name": "Online Protections for Minors", "region": "US-FL", "article_or_section": "", "source": "https://www.flsenate.gov/Session/Bill/2024/3"}}
{"id": "bed49130-cc9b-4f6d-9ba5-5142baaf8b0b", "text": "## Citations - Statutes (1)  \n| Citation | Catchline | Location in Bill |\n|---|---|---|\n| 501.1737 | | Page 1 (PDF) |\nPOSTED 1/5/2024 AT 6:48 PM", "metadata": {"h2": "Citations - Statutes (1)", "source_path": "data/kb_raw/Florida state law.txt", "h1": "", "h3": "", "law_name": "Online Protections for Minors", "region": "US-FL", "article_or_section": "", "source": "https://www.flsenate.gov/Session/Bill/2024/3"}}
{"id": "0be6135f-30ae-47aa-90ab-694178ca6d5c", "text": "## HB 3, ORIGINAL FILED VERSION", "metadata": {"h2": "HB 3, ORIGINAL FILED VERSION", "source_path": "data/kb_raw/Florida state law.txt", "h1": "", "h3": "", "law_name": "Online Protections for Minors", "region": "US-FL", "article_or_section": "", "source": "https://www.flsenate.gov/Session/Bill/2024/3"}}
{"id": "b9c83a0e-59c4-4d4e-ae35-ae78d143bde6", "text": "## Related Bills (8)  \n| Bill Number | Subject | Filed By | Relationship | Last Action and Location | Track Bills |\n|---------------|-------------------------------------------------------------|-------------------------------------------------------|----------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------|\n| H1491 | Pub. Rec./Investigations by the Department of Legal Affairs | Regulatory Reform & Economic Development Subcommittee | Linked | Last Action: 4/3/2024 Chapter No. 2024-54; companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) | |\n| S 1792 | Online Access to Materials Harmful to Minors | Grall | Similar | Last Action: 3/8/2024 S Died in Fiscal Policy, companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) | |\n| H1 | Social Media Use for Minors | Judiciary Committee | Compare | Last Action: 3/1/2024 Vetoed by Governor; companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42); companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-2024-54) | |\n| H207 | Social Media Protection for Minors | Rayner, Sirois | Compare | Last Action: 3/8/2024 HDied on Second Reading Calendar | |\n| S 454 | Protection of Minors on Social Media Platforms | Garcia | Compare | Last Action: 3/8/2024 S Died in Commerce and Tourism, companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) | |\n| S 1430 | Social Media Protection for Minors | Book | Compare | Last Action: 3/8/2024 S Died in Judiciary | |\n| S 1788 | Age Verification for Social Media Platform Accounts | Grall | Compare | Last Action: 3/8/2024 S Died in Fiscal Policy, companion bill(s) passed, see CS/CS/HB 3 (Ch. 2024-42) | |\n| S 1794 | Public Records/Investigations by the Department of Legal Affairs | Grall | Compare | Last Action: 3/8/2024 S Died in Fiscal Policy, companion bill(s) passed, see CS/CS/HB 1491 (Ch. 2024-54) | |", "metadata": {"h2": "Related Bills (8)", "source_path": "data/kb_raw/Florida state law.txt", "h1": "", "h3": "", "law_name": "Online Protections for Minors", "region": "US-FL", "article_or_section": "", "source": "https://www.flsenate.gov/Session/Bill/2024/3"}}
{"id": "3c302b40-b31a-497a-b572-07c6ec19c4e6", "text": "## Committee Amendments (1)  \nOf course. Here is the reconstructed table:  \n| Amendment | Sponsor | Filed | Last Committee Action | Format |\n|---|---|---|---|---|\n| 427693 - Amendment<br>Remove lines 34-54 and insert: | Tramont | 1/10/2024<br><br>5:29 PM | Adopted without Objection 1/11/2024 | PDF |", "metadata": {"h2": "Committee Amendments (1)", "source_path": "data/kb_raw/Florida state law.txt", "h1": "", "h3": "", "law_name": "Online Protections for Minors", "region": "US-FL", "article_or_section": "", "source": "https://www.flsenate.gov/Session/Bill/2024/3"}}
{"id": "b3327fbd-860e-4e43-9548-6a92f1298228", "text": "## Citations - Statutes (1)\n| Citation | Catchline | Location in Bill |\n|---|---|---|\n| 501.1737 | Age verification for online access to materials harmful to minors. | Page 1 (PDF) |  \nDisclaimer: The information on this system is unverified. The journals or printed bills of the respective chambers should be consulted for official purposes.  \nCopyright © 2000- 2025 State of Florida.", "metadata": {"h2": "Citations - Statutes (1)", "source_path": "data/kb_raw/Florida state law.txt", "h1": "", "h3": "", "law_name": "Online Protections for Minors", "region": "US-FL", "article_or_section": "", "source": "https://www.flsenate.gov/Session/Bill/2024/3"}}
{"id": "c975bced-fbda-4c2c-bb7e-cbee1d4273b6", "text": "## 18 U.S. Code § 2258A - Reporting requirements of providers  \nU.S. Code  \nNotes  \n(a) DUTY TO REPORT.-  \n(1) IN GENERAL.-  \n(A) Duty.-In order to reduce the proliferation of online child sexual exploitation and to prevent the online sexual exploitation of children, a provider-  \n(i) shall, as soon as reasonably possible after obtaining actual knowledge of any facts or circumstances described in paragraph (2) (A), take the actions described in subparagraph (B); and  \n- (ii) may, after obtaining actual knowledge of any facts or circumstances described in paragraph (2)(B), take the actions described in subparagraph (B).  \n(B) Actions described.-The actions described in this subparagraph are  \n-  \n(i) providing to the CyberTipline of NCMEC, or any successor to the CyberTipline operated by NCMEC, the mailing address, telephone number, facsimile number, electronic mailing address of, and individual point of contact for, such provider; and  \n(ii) making a report of such facts or circumstances to the CyberTipline, or any successor to the CyberTipline operated by NCMEC.", "metadata": {"h2": "18 U.S. Code § 2258A - Reporting requirements of providers", "source_path": "data/kb_raw/US law on reporting child sexual abuse content to NCMEC -.txt", "h1": "", "h3": "", "law_name": "18 U.S.C. § 2258A - Reporting requirements of providers", "region": "US", "article_or_section": "", "source": "https://www.law.cornell.edu/uscode/text/18/2258A"}}
{"id": "558235d4-7905-4711-b050-0849d590fc61", "text": "## (2) FACTS OR CIRCUMSTANCES.-", "metadata": {"h2": "(2) FACTS OR CIRCUMSTANCES.-", "source_path": "data/kb_raw/US law on reporting child sexual abuse content to NCMEC -.txt", "h1": "", "h3": "", "law_name": "18 U.S.C. § 2258A - Reporting requirements of providers", "region": "US", "article_or_section": "", "source": "https://www.law.cornell.edu/uscode/text/18/2258A"}}
{"id": "7d237050-765b-4188-a1b5-178ae4b30117", "text": "## (A) Apparent violations.-  \nThe facts or circumstances described in this subparagraph are any facts or circumstances from which there is an apparent violation of section 2251, 2251A, 2252, 2252A, 2252B, or 2260 that involves child pornography, of section 1591 (if the violation involves a minor), or of [1] 2422(b).", "metadata": {"h2": "(A) Apparent violations.-", "source_path": "data/kb_raw/US law on reporting child sexual abuse content to NCMEC -.txt", "h1": "", "h3": "", "law_name": "18 U.S.C. § 2258A - Reporting requirements of providers", "region": "US", "article_or_section": "", "source": "https://www.law.cornell.edu/uscode/text/18/2258A"}}
{"id": "969232c9-15b8-4093-8b69-0eb261b7df1d", "text": "## (B) Imminent violations.-  \nThe facts or circumstances described in this subparagraph are any facts or circumstances which indicate a violation of any of the sections described in subparagraph (A) involving child pornography may be planned or imminent.  \n- (b) CONTENTS OF REPORT.In an effort to prevent the future sexual victimization of children, and to the extent the information is within the custody or control of a provider, the facts and circumstances included in each report under subsection (a)(1) may, at the sole discretion of the provider, include the following information:", "metadata": {"h2": "(B) Imminent violations.-", "source_path": "data/kb_raw/US law on reporting child sexual abuse content to NCMEC -.txt", "h1": "", "h3": "", "law_name": "18 U.S.C. § 2258A - Reporting requirements of providers", "region": "US", "article_or_section": "", "source": "https://www.law.cornell.edu/uscode/text/18/2258A"}}
{"id": "ebad1a11-070d-450c-8d4c-2c34f0c2c6b9", "text": "## (1) INFORMATION ABOUT THE INVOLVED INDIVIDUAL.-  \nInformation relating to the identity of any individual who appears to have violated or plans to violate a Federal law described in subsection (a)(2), which may, to the extent reasonably practicable, include the electronic mail address, Internet Protocol address, uniform resource locator, payment information (excluding personally identifiable information), or any other identifying information, including self-reported identifying information.", "metadata": {"h2": "(1) INFORMATION ABOUT THE INVOLVED INDIVIDUAL.-", "source_path": "data/kb_raw/US law on reporting child sexual abuse content to NCMEC -.txt", "h1": "", "h3": "", "law_name": "18 U.S.C. § 2258A - Reporting requirements of providers", "region": "US", "article_or_section": "", "source": "https://www.law.cornell.edu/uscode/text/18/2258A"}}
{"id": "7eb6f224-a66b-4bfd-9adc-e468a7a6989d", "text": "## (3) GEOGRAPHIC LOCATION INFORMATION.-  \nInformation relating to the geographic location of the involved individual or website, which may include the Internet Protocol address or verified address, or, if not reasonably available, at least one form of geographic identifying information, including area code or zip code, provided by the customer or subscriber, or stored or obtained by the provider.", "metadata": {"h2": "(3) GEOGRAPHIC LOCATION INFORMATION.-", "source_path": "data/kb_raw/US law on reporting child sexual abuse content to NCMEC -.txt", "h1": "", "h3": "", "law_name": "18 U.S.C. § 2258A - Reporting requirements of providers", "region": "US", "article_or_section": "", "source": "https://www.law.cornell.edu/uscode/text/18/2258A"}}
{"id": "9d3890e8-cab0-4690-aa53-07890058fb59", "text": "## (4) VISUAL DEPICTIONS OF APPARENT CHILD PORNOGRAPHY.-  \nAny visual depiction of apparent child pornography or other content relating to the incident such report is regarding.  \n- (5) COMPLETE COMMUNICATION.The complete communication containing any visual depiction of apparent child pornography or other content, including-\n- (A) any data or information regarding the transmission of the communication; and\n- (B) any visual depictions, data, or other digital files contained in, or attached to, the communication.\n- (c) FORWARDING OF REPORT TO LAW ENFORCEMENT.Pursuant to its clearinghouse role as a private, nonprofit organization, and at the conclusion of its review in furtherance of its nonprofit mission, NCMEC shall make available each report made under subsection (a)(1) to one or more of the following law enforcement agencies:\n- (1) Any Federal law enforcement agency that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes.\n- (2) Any State or local law enforcement agency that is involved in the investigation of child sexual exploitation.\n- (3) A foreign law enforcement agency designated by the Attorney General under subsection (d)(3) or a foreign law enforcement agency that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes.\n- (d) ATTORNEY GENERAL RESPONSIBILITIES.-\n- (1) IN GENERAL.-\n- (i) to an attorney for the government for use in the performance of the official duties of that attorney;\n- (ii) to such officers and employees of that law enforcement agency, as may be necessary in the performance of their investigative and recordkeeping functions;\n- (iii) to such other government personnel (including personnel of a State or subdivision of a State) as are determined to be necessary by an attorney for the government to assist the attorney in the performance of the official duties of the attorney in enforcing Federal criminal law;\n- (iv) if the report discloses a violation of State criminal law, to an appropriate official of a State or subdivision of a State for the purpose of enforcing such State law;\n- (v) to a defendant in a criminal case or the attorney for that defendant, subject to the terms and limitations under section 3509(m) or a similar State law, to the extent the information relates to a criminal charge pending against that defendant;\n- (vi) subject to subparagraph (B), to a provider if necessary to facilitate response to legal process issued in connection to a criminal investigation, prosecution, or post-conviction remedy relating to that report; and  \nThe Attorney General shall enforce this section.", "metadata": {"h2": "(4) VISUAL DEPICTIONS OF APPARENT CHILD PORNOGRAPHY.-", "source_path": "data/kb_raw/US law on reporting child sexual abuse content to NCMEC -.txt", "h1": "", "h3": "", "law_name": "18 U.S.C. § 2258A - Reporting requirements of providers", "region": "US", "article_or_section": "", "source": "https://www.law.cornell.edu/uscode/text/18/2258A"}}
{"id": "b8b392e6-d01d-479f-a7c7-869464785b13", "text": "## (2) DESIGNATION OF FEDERAL AGENCIES.-  \nThe Attorney General may designate a Federal law enforcement agency or agencies to which a report shall be forwarded under subsection (c)(1).  \n(3) DESIGNATION OF FOREIGN AGENCIES.- The Attorney General may-  \n(A) in consultation with the Secretary of State, designate foreign law enforcement agencies to which a report may be forwarded under subsection (c)(3);  \n(B) establish the conditions under which such a report may be forwarded to such agencies; and  \n(C) develop a process for foreign law enforcement agencies to request assistance from Federal law enforcement agencies in obtaining evidence related to a report referred under subsection (c)(3).", "metadata": {"h2": "(2) DESIGNATION OF FEDERAL AGENCIES.-", "source_path": "data/kb_raw/US law on reporting child sexual abuse content to NCMEC -.txt", "h1": "", "h3": "", "law_name": "18 U.S.C. § 2258A - Reporting requirements of providers", "region": "US", "article_or_section": "", "source": "https://www.law.cornell.edu/uscode/text/18/2258A"}}
{"id": "d6e0a7a0-a987-4dc8-b261-0f276c4b6209", "text": "## (4) REPORTING DESIGNATED FOREIGN AGENCIES.-  \nThe Attorney General may maintain and make available to the Department of State, NCMEC, providers, the Committee on the Judiciary of the Senate, and the Committee on the Judiciary of the House of Representatives a list of the foreign law enforcement agencies designated under paragraph (3).", "metadata": {"h2": "(4) REPORTING DESIGNATED FOREIGN AGENCIES.-", "source_path": "data/kb_raw/US law on reporting child sexual abuse content to NCMEC -.txt", "h1": "", "h3": "", "law_name": "18 U.S.C. § 2258A - Reporting requirements of providers", "region": "US", "article_or_section": "", "source": "https://www.law.cornell.edu/uscode/text/18/2258A"}}
{"id": "22840a6d-e082-4a99-bbe0-6d3e73f31039", "text": "## (5) NOTIFICATION TO PROVIDERS.-  \n(A) In general.-NCMEC may notify a provider of the information described in subparagraph (B), if-  \n(i) a provider notifies NCMEC that the provider is making a report under this section as the result of a request by a foreign law enforcement agency; and  \n(ii) NCMEC forwards the report described in clause (i) to-  \n(I) the requesting foreign law enforcement agency; or  \n(II) another agency in the same country designated by the Attorney General under paragraph (3) or that has an established relationship with the Federal Bureau of Investigation, U.S. Immigration and Customs Enforcement, or INTERPOL and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes.  \n(B) Information described.-The information described in this subparagraph is-  \n(i) the identity of the foreign law enforcement agency to which the report was forwarded; and  \n(ii) the date on which the report was forwarded.", "metadata": {"h2": "(5) NOTIFICATION TO PROVIDERS.-", "source_path": "data/kb_raw/US law on reporting child sexual abuse content to NCMEC -.txt", "h1": "", "h3": "", "law_name": "18 U.S.C. § 2258A - Reporting requirements of providers", "region": "US", "article_or_section": "", "source": "https://www.law.cornell.edu/uscode/text/18/2258A"}}
{"id": "80ed960b-bd34-456e-992e-61b71a9f1dbd", "text": "## (C) Notification of inability to forward report.-  \nIf a provider notifies NCMEC that the provider is making a report under this section as the result of a request by a foreign law enforcement agency and NCMEC is unable to forward the report as described in subparagraph (A)(ii), NCMEC shall notify the provider that NCMEC was unable to forward the report.  \n(e) FAILURE TO REPORT.- A provider that knowingly and willfully fails to make a report required under subsection (a)(1) shall be fined-  \n(1) in the case of an initial knowing and willful failure to make a report, not more than $850,000 in the case of a provider with not less than 100,000,000 monthly active users or $600,000 in the case of a provider with less than 100,000,000 monthly active users; and  \n(2) in the case of any second or subsequent knowing and willful failure to make a report, not more than $1,000,000 in the case of a provider with not less than 100,000,000 monthly active users or $850,000 in the case of a provider with less than 100,000,000 monthly active users.  \n(f) PROTECTION OF PRIVACY.- Nothing in this section shall be construed to require a provider to-  \n(1) monitor any user, subscriber, or customer of that provider;  \n(2) monitor the content of any communication of any person described in paragraph (1); or  \n(3) affirmatively search, screen, or scan for facts or circumstances described in sections (a) and (b).  \n(g) CONDITIONS OF DISCLOSURE INFORMATION CONTAINED WITHIN REPORT.-  \n(1) IN GENERAL.-  \nExcept as provided in paragraph (2), a law enforcement agency that receives a report under subsection (c) shall not disclose any information contained in that report.  \n(2) PERMITTED DISCLOSURES BY LAW ENFORCEMENT.-  \n(A) In general.-A law enforcement agency may disclose information in a report received under subsection (c)-  \n(vii) as ordered by a court upon a showing of good cause and pursuant to any protective orders or other conditions that the court may impose.", "metadata": {"h2": "(C) Notification of inability to forward report.-", "source_path": "data/kb_raw/US law on reporting child sexual abuse content to NCMEC -.txt", "h1": "", "h3": "", "law_name": "18 U.S.C. § 2258A - Reporting requirements of providers", "region": "US", "article_or_section": "", "source": "https://www.law.cornell.edu/uscode/text/18/2258A"}}
{"id": "5d8a5396-1a38-4fcb-a9b3-3d00f0790bdc", "text": "## (B) Limitation.-  \nNothing in subparagraph (A)(vi) authorizes a law enforcement agency to provide visual depictions of apparent child pornography to a provider.  \n- (3) PERMITTED DISCLOSURES BY NCMEC.NCMEC may disclose by mail, electronic transmission, or other reasonable means, information received in a report under subsection (a) only to-\n- (A) any Federal law enforcement agency designated by the Attorney General under subsection (d)(2) or that is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes;\n- (B) any State, local, or tribal law enforcement agency involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes;  \n(C) any foreign law enforcement agency designated by the Attorney General under subsection (d)(3) or that has an established relationship with the Federal Bureau of Investigation, Immigration and Customs Enforcement, or INTERPOL, and is involved in the investigation of child sexual exploitation, kidnapping, or enticement crimes;  \n- (D) a provider as described in section 2258C; and\n- (E) respond to legal process, as necessary.", "metadata": {"h2": "(B) Limitation.-", "source_path": "data/kb_raw/US law on reporting child sexual abuse content to NCMEC -.txt", "h1": "", "h3": "", "law_name": "18 U.S.C. § 2258A - Reporting requirements of providers", "region": "US", "article_or_section": "", "source": "https://www.law.cornell.edu/uscode/text/18/2258A"}}
{"id": "ef0fd9e4-4eff-4df8-9388-c1e37777d038", "text": "## (4) PERMITTED DISCLOSURE BY A PROVIDER.-  \nA provider that submits a report under subsection (a)(1) may disclose by mail, electronic transmission, or other reasonable means, information, including visual depictions contained in the report, in a manner consistent with permitted disclosures under paragraphs (3) through (8) of section 2702(b) only to a law enforcement agency described in subparagraph (A), (B), or (C) of paragraph (3), to NCMEC, or as necessary to respond to legal process.", "metadata": {"h2": "(4) PERMITTED DISCLOSURE BY A PROVIDER.-", "source_path": "data/kb_raw/US law on reporting child sexual abuse content to NCMEC -.txt", "h1": "", "h3": "", "law_name": "18 U.S.C. § 2258A - Reporting requirements of providers", "region": "US", "article_or_section": "", "source": "https://www.law.cornell.edu/uscode/text/18/2258A"}}
{"id": "941bea0e-9b09-4e94-9b2b-d214d806e4af", "text": "## (h) PRESERVATION.-", "metadata": {"h2": "(h) PRESERVATION.-", "source_path": "data/kb_raw/US law on reporting child sexual abuse content to NCMEC -.txt", "h1": "", "h3": "", "law_name": "18 U.S.C. § 2258A - Reporting requirements of providers", "region": "US", "article_or_section": "", "source": "https://www.law.cornell.edu/uscode/text/18/2258A"}}
{"id": "9d933892-55f2-472e-bf18-a3306e2aeb31", "text": "## (1) IN GENERAL.-  \nFor the purposes of this section, a completed submission by a provider of a report to the CyberTipline under subsection (a)(1) shall be treated as a request to preserve the contents provided in the report for 1 year after the submission to the CyberTipline.", "metadata": {"h2": "(1) IN GENERAL.-", "source_path": "data/kb_raw/US law on reporting child sexual abuse content to NCMEC -.txt", "h1": "", "h3": "", "law_name": "18 U.S.C. § 2258A - Reporting requirements of providers", "region": "US", "article_or_section": "", "source": "https://www.law.cornell.edu/uscode/text/18/2258A"}}
{"id": "b2e474f8-1c06-4c6d-b915-8991276d6278", "text": "## (2) PRESERVATION OF COMMINGLED CONTENT.-  \nPursuant to paragraph (1), a provider shall preserve any visual depictions, data, or other digital files that are reasonably accessible and may provide context or additional information about the reported material or person.", "metadata": {"h2": "(2) PRESERVATION OF COMMINGLED CONTENT.-", "source_path": "data/kb_raw/US law on reporting child sexual abuse content to NCMEC -.txt", "h1": "", "h3": "", "law_name": "18 U.S.C. § 2258A - Reporting requirements of providers", "region": "US", "article_or_section": "", "source": "https://www.law.cornell.edu/uscode/text/18/2258A"}}
{"id": "1c5167c6-79bb-4cb7-91e9-ec8b9e49579b", "text": "## (3) PROTECTION OF PRESERVED MATERIALS.-  \nA provider preserving materials under this section shall maintain the materials in a secure location and take appropriate steps to limit access by agents or employees of the service to the materials to that access necessary to comply with the requirements of this subsection.", "metadata": {"h2": "(3) PROTECTION OF PRESERVED MATERIALS.-", "source_path": "data/kb_raw/US law on reporting child sexual abuse content to NCMEC -.txt", "h1": "", "h3": "", "law_name": "18 U.S.C. § 2258A - Reporting requirements of providers", "region": "US", "article_or_section": "", "source": "https://www.law.cornell.edu/uscode/text/18/2258A"}}
{"id": "16d10740-6c33-46f3-95f9-0bde744ec7e6", "text": "## (4) AUTHORITIES AND DUTIES NOT AFFECTED.-  \nNothing in this section shall be construed as replacing, amending, or otherwise interfering with the authorities and duties under section 2703.", "metadata": {"h2": "(4) AUTHORITIES AND DUTIES NOT AFFECTED.-", "source_path": "data/kb_raw/US law on reporting child sexual abuse content to NCMEC -.txt", "h1": "", "h3": "", "law_name": "18 U.S.C. § 2258A - Reporting requirements of providers", "region": "US", "article_or_section": "", "source": "https://www.law.cornell.edu/uscode/text/18/2258A"}}
{"id": "f24341ff-3345-402b-9dbd-2381f1dfb8f9", "text": "## (5) EXTENSION OF PRESERVATION.-  \nA provider of a report to the CyberTipline under subsection (a)(1) may voluntarily preserve the contents provided in the report (including any comingled content described in paragraph (2)) for longer than 1 year after the submission to the CyberTipline for the purpose of reducing the proliferation of online child sexual exploitation or preventing the online sexual exploitation of children.", "metadata": {"h2": "(5) EXTENSION OF PRESERVATION.-", "source_path": "data/kb_raw/US law on reporting child sexual abuse content to NCMEC -.txt", "h1": "", "h3": "", "law_name": "18 U.S.C. § 2258A - Reporting requirements of providers", "region": "US", "article_or_section": "", "source": "https://www.law.cornell.edu/uscode/text/18/2258A"}}
{"id": "e76df8fa-ea20-4948-93f9-2a59d767e03e", "text": "## (6) METHOD OF PRESERVATION.-  \nNot later than 1 year after the date of enactment of this paragraph, a provider of a report to the CyberTipline under subsection (a)(1) shall preserve materials under this subsection in a manner that is consistent with the most recent version of the Cybersecurity Framework developed by the National Institute of Standards and Technology, or any successor thereto.  \n[1] So in original. Probably should be followed by 'section'.", "metadata": {"h2": "(6) METHOD OF PRESERVATION.-", "source_path": "data/kb_raw/US law on reporting child sexual abuse content to NCMEC -.txt", "h1": "", "h3": "", "law_name": "18 U.S.C. § 2258A - Reporting requirements of providers", "region": "US", "article_or_section": "", "source": "https://www.law.cornell.edu/uscode/text/18/2258A"}}
{"id": "a61507d4-bb52-4313-8358-2cbd60dbb5af", "text": "## Editorial Notes", "metadata": {"h2": "Editorial Notes", "source_path": "data/kb_raw/US law on reporting child sexual abuse content to NCMEC -.txt", "h1": "", "h3": "", "law_name": "18 U.S.C. § 2258A - Reporting requirements of providers", "region": "US", "article_or_section": "", "source": "https://www.law.cornell.edu/uscode/text/18/2258A"}}
{"id": "94e23c61-666a-46f5-8cad-5886d1b41a86", "text": "## Statutory Notes and Related Subsidiaries", "metadata": {"h2": "Statutory Notes and Related Subsidiaries", "source_path": "data/kb_raw/US law on reporting child sexual abuse content to NCMEC -.txt", "h1": "", "h3": "", "law_name": "18 U.S.C. § 2258A - Reporting requirements of providers", "region": "US", "article_or_section": "", "source": "https://www.law.cornell.edu/uscode/text/18/2258A"}}
{"id": "c928b2ff-ad77-4b1f-bbf5-aa8d4e243e47", "text": "## GUIDELINES  \nPub. L. 118-59, § 4(b), May 7, 2024, 138 Stat. 1017, provided that: 'Not later than 180 days after the date of enactment of this Act [May 7, 2024], the National Center for Missing &amp; Exploited Children may issue guidelines, as appropriate, to providers required or permitted to take actions described in section 2258A(a)(1)(B) of title 18, United States Code, on the relevant identifiers for content that may indicate sex trafficking of children, as described in section 1591 of that title, or enticement, as described in section 2422(b) of that title.'", "metadata": {"h2": "GUIDELINES", "source_path": "data/kb_raw/US law on reporting child sexual abuse content to NCMEC -.txt", "h1": "", "h3": "", "law_name": "18 U.S.C. § 2258A - Reporting requirements of providers", "region": "US", "article_or_section": "", "source": "https://www.law.cornell.edu/uscode/text/18/2258A"}}
{"id": "12624e37-042a-4e89-9f67-52a6ebd79108", "text": "## Utah Social Media Regulation Act  \nS.B. 152 and H.B. 311 , collectively known as the Utah Social Media Regulation Act , were social media bills that were passed by the Utah State Legislature in March 2023. The bills would've collectively imposed restrictions on how social networking services serve minors in the state of Utah, including mandatory age verification, and restrictions on data collection, algorithmic recommendations, and on when social networks would've been accessible to minors.  \nThe Act was intended to take effect in March 2024. However, following a lawsuit over the Act by NetChoice, the Utah attorney general stated in January 2024 that its implementation had been delayed to October 2024, but was likely to be repealed and amended. On September 10, 2024 Chief Judge Robert J. Shelby issued a written order granting a request from NetChoice, a tech industry group, for a preliminary injunction, meaning that Utah will be unable to enforce its social media law as litigation plays out. [1] The law was appealed to the 10th Circuit on October 11, 2024 and is awaiting a decision. [2]", "metadata": {"h2": "Utah Social Media Regulation Act", "source_path": "data/kb_raw/Utah state law.txt", "h1": "", "h3": "", "law_name": "Utah Social Media Regulation Act", "region": "US-UT", "article_or_section": "", "source": "https://le.utah.gov/~2023/bills/static/SB0152.html"}}
{"id": "7379bb5e-cb50-40e6-9c3a-fe6c5bf8f220", "text": "## Provisions  \nThe Act comprises two bills, S.B. 152 and H.B. 311, which respectively regulate access to social network accounts registered to minors, and impose obligations on social networking services to follow design practices that protect the privacy of minors. [3][4] The bills would apply to social networks with more than 5 million active users in the United States. [5]  \nSocial networking services would've verified the age of all users in the state of Utah, or else their account must've been deleted. The Act does not specify a specific method of age verification. Users who are under 18 must have consent from a parent or guardian to open an account, and the parent must be able to have access to the account and its data for monitoring. [6]  \nUnless required to comply with state or federal law, social networks were prohibited from collecting data based on the activity of minors, and may've not displayed targeted advertising or algorithmic recommendations of content, users, or groups to minors. A social network must not allow minors to access the service between the hours of 10:30 p.m., and 6:30 a.m. without parental consent. [3][4] H.B. 311 prohibits social networks from exposing features to minors that cause them to have an \"addiction\" to the platform; the service must perform quarterly audits, and may be sued by users for harms caused by providing \"addictive\" features; there is a rebuttable presumption of harm if the plaintiff is 16 or younger. [3][4]  \nThe bills prescribed fines of $2,500 per-violation for violations of the provisions of S.B. 152, and up to $250,000 in liabilities (plus fines of $2,500 per-user) for violations of the addiction rules. [7]", "metadata": {"h2": "Provisions", "source_path": "data/kb_raw/Utah state law.txt", "h1": "", "h3": "", "law_name": "Utah Social Media Regulation Act", "region": "US-UT", "article_or_section": "", "source": "https://le.utah.gov/~2023/bills/static/SB0152.html"}}
{"id": "520f9f47-2dbd-4213-add5-fb2b106df2dc", "text": "## History  \nThe two bills were passed in early-March 2023, [8] and signed by Governor Spencer Cox on March 23, 2023. [3][4] Cox cited studies linking social media addiction to increases in depression and suicide among youth. [5] They were originally intended to take effect on March 1, 2024. [3][4] In the wake of a lawsuit in Arkansas by the trade association NetChoice over a similar bill, state senator and bill author Mike McKell stated that he planned to introduce amendments when the legislature resumed in 2024. [9]  \nIn December 2023, NetChoice filed a lawsuit in Utah seeking to block the Act, citing that its definition of a social network was too vague, and that it \"restricts who can express themselves, what can be said, and when and how speech on covered websites can occur, down to the very hours of the day minors can use covered websites. The First Amendment, reinforced by decades of precedent, allows none of this.\" [5] In regards to its age verification requirements, NetChoice argued that \"it may not be enough to simply verify the age of whatever person may be listed on a form of identification (even if they have such a record) because that record may not accurately reflect who the individual actually is.\" The office of the attorney general stated that the state was \"reviewing the lawsuit but remains intently focused on the goal of this legislation: Protecting young people from negative and harmful effects of social media use.\" [5]  \nIn January 2024, Attorney General Sean Reyes asked the court to delay a hearing over the bill, stating that its effective date had been delayed to October 2024, and that the legislature planned to repeal and replace the bills. [10][11]", "metadata": {"h2": "History", "source_path": "data/kb_raw/Utah state law.txt", "h1": "", "h3": "", "law_name": "Utah Social Media Regulation Act", "region": "US-UT", "article_or_section": "", "source": "https://le.utah.gov/~2023/bills/static/SB0152.html"}}
{"id": "5e46b9b1-53ff-46ba-b480-d135d33877b0", "text": "## See also  \n- Age appropriate design code", "metadata": {"h2": "See also", "source_path": "data/kb_raw/Utah state law.txt", "h1": "", "h3": "", "law_name": "Utah Social Media Regulation Act", "region": "US-UT", "article_or_section": "", "source": "https://le.utah.gov/~2023/bills/static/SB0152.html"}}
